## GPUë¬¸ì œë¡œ êµ¬ê¸€ colabì—ì„œ ì‹¤í–‰í•¨

import cv2
import os
import torch
from transformers import Blip2Processor, Blip2ForConditionalGeneration
from ultralytics import YOLO

# âœ… YOLO & BLIP ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
yolo_model = YOLO("yolov8n.pt")  # YOLOv8 ëª¨ë¸
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… BLIP-2 ëª¨ë¸ ë³€ê²½
processor = Blip2Processor.from_pretrained("Salesforce/blip2-opt-2.7b")
blip_model = Blip2ForConditionalGeneration.from_pretrained(
    "Salesforce/blip2-opt-2.7b",
    torch_dtype=torch.float16,  # ë©”ëª¨ë¦¬ ìµœì í™”
    low_cpu_mem_usage=True
).to(device)

# âœ… í´ë” ì„¤ì •
FRAME_DIR = "frames"
RESULTS_DIR = "detections"
CAPTION_DIR = "captions"
os.makedirs(RESULTS_DIR, exist_ok=True)
os.makedirs(CAPTION_DIR, exist_ok=True)

def detect_objects_and_generate_caption(image_path):
    """YOLOë¡œ ê°ì²´ íƒì§€ + BLIP-2ë¡œ ì„¤ëª… ìƒì„±"""
    img = cv2.imread(image_path)
    
    # âœ… YOLO íƒì§€
    results = yolo_model(img)
    detected_objects = []
    
    for result in results:
        for box in result.boxes:
            class_id = int(box.cls[0])
            label = yolo_model.names[class_id]  # ê°ì²´ ì´ë¦„
            detected_objects.append(label)
    
    # âœ… BLIP-2 ì„¤ëª… ìƒì„±
    raw_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    inputs = processor(images=raw_image, return_tensors="pt").to(device)

    with torch.no_grad():
        generated_ids = blip_model.generate(**inputs, max_length=50)
        blip_caption = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]

    # âœ… ìµœì¢… ì„¤ëª… ìƒì„±
    combined_caption = f"íƒì§€ëœ ê°ì²´: {', '.join(detected_objects)}. ì„¤ëª…: {blip_caption}"

    # âœ… íƒì§€ ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥
    img_with_boxes = results[0].plot()
    save_path = os.path.join(RESULTS_DIR, os.path.basename(image_path))
    cv2.imwrite(save_path, img_with_boxes)

    # âœ… ì„¤ëª… ì €ì¥
    caption_path = os.path.join(CAPTION_DIR, f"{os.path.basename(image_path)}.txt")
    with open(caption_path, "w", encoding="utf-8") as f:
        f.write(combined_caption)

    print(f"âœ… ë¶„ì„ ì™„ë£Œ: {os.path.basename(image_path)} -> {combined_caption}")

def process_all_images():
    """ëª¨ë“  í”„ë ˆì„ì„ ë¶„ì„í•˜ì—¬ ê°ì²´ íƒì§€ + ì„¤ëª… ìƒì„±"""
    for filename in os.listdir(FRAME_DIR):
        if filename.endswith(".jpg"):
            image_path = os.path.join(FRAME_DIR, filename)
            detect_objects_and_generate_caption(image_path)

if __name__ == "__main__":
    print("ğŸš€ YOLO ê°ì²´ íƒì§€ + BLIP-2 ì„¤ëª… ìƒì„± ì‹œì‘...")
    process_all_images()
    print("ğŸ‰ ëª¨ë“  í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ!")
